{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e17c9b6c",
   "metadata": {},
   "source": [
    "# Web Scraper Assessment\n",
    "\n",
    "Using Python 3 and Selenium, write a script that opens the web page\n",
    "> https://webscraper.io/test-sites/e-commerce/allinone-popup-links/computers/laptops \n",
    "\n",
    "\n",
    "- Grabs the price of the 256GB and 1024GB versions of the first 10 laptops. \n",
    "- Write these prices as a row along with the \n",
    "    - Name\n",
    "    - Description\n",
    "    - Number of reviews for the item to a CSV file. \n",
    "\n",
    "Once completed, zip the python file and send it to us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d4281e",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a23466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c727e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "Driver [C:\\Users\\Alec\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# set up splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a182707",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://webscraper.io/test-sites/e-commerce/allinone-popup-links/computers/laptops'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8e61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the soup object\n",
    "html = browser.html\n",
    "laptop_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "# isolate the div will all of the laptops\n",
    "all_laptops = laptop_soup.find_all('div', class_='col-sm-4 col-lg-4 col-md-4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd041ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def links_to_list(num_laptops):\n",
    "    \n",
    "    '''\n",
    "    This function accepts an integer for the number of links / laptops to scrape from the front page of the test-scrape website\n",
    "    \n",
    "    :param: num_laptops - INT - the number of laptop links\n",
    "    '''\n",
    "    \n",
    "    link_list = []\n",
    "\n",
    "    for i, laptop in enumerate(all_laptops[:num_laptops]):\n",
    "        #isolate the link\n",
    "        a_tag = laptop.find('a')\n",
    "        # extract the url from the onclick attribute, slice out the link\n",
    "        element_link_partial = a_tag['onclick'].split(\"'\")[1]\n",
    "        # combine with string to construct full link\n",
    "        element_link_full = f'https://webscraper.io{element_link_partial}'\n",
    "        # add to list for later use\n",
    "        link_list.append(element_link_full)\n",
    "        \n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d4247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For each link in the list:\n",
    "    - navigate to the page\n",
    "    - slice the desired information, manipulating HTML as needed for varying values\n",
    "    - assign information to variables\n",
    "    - assemble dictionary\n",
    "    - add dictionary to list for conversion to Dataframe in later step\n",
    "'''\n",
    "\n",
    "\n",
    "# set list to hold laptop information\n",
    "information_list = []\n",
    "\n",
    "laptop_list = links_to_list(10)\n",
    "\n",
    "for i in range(0,len(laptop_list)):\n",
    "    \n",
    "    # set up link for browser and soup object\n",
    "    link = laptop_list[i]\n",
    "    browser.visit(f'{link}')\n",
    "\n",
    "    # create soup object now that HTML has changed (from front page)\n",
    "    html = browser.html\n",
    "    laptop_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # extract the static information\n",
    "    description = laptop_soup.find('p', class_='description').get_text().replace(',','')\n",
    "    \n",
    "    name_div = laptop_soup.find('div',class_='caption')\n",
    "    name = name_div.find_all('h4')[1].get_text()\n",
    "    \n",
    "    # isolate number of reviews, remove whitespace, take only numerical digits\n",
    "    num_reviews = laptop_soup.find('div',class_='ratings').get_text().strip().split(' ')[0]\n",
    "    \n",
    "    # find the button for 256GB price, click it\n",
    "    browser.find_by_value('256').click()\n",
    "    \n",
    "    # reset soup object due to changes in HTML\n",
    "    html = browser.html\n",
    "    laptop_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # set the price variable - clean the $ characters out for dtype changes later\n",
    "    price_256 = laptop_soup.find('h4',class_='pull-right price').get_text().replace('$','')\n",
    "\n",
    "    # find the button for 1024GB price, click it\n",
    "    browser.find_by_value('1024').click()\n",
    "\n",
    "    # reset soup object due to changes in HTML\n",
    "    html = browser.html\n",
    "    laptop_soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # set the price variable - clean the $ characters out for dtype changes later\n",
    "    price_1024 = laptop_soup.find('h4',class_='pull-right price').get_text().replace('$','')\n",
    "    laptop_info = {\n",
    "        'name': name,\n",
    "        'price_256GB_usd': price_256,\n",
    "        'price_1024GB_usd': price_1024,\n",
    "        'description': description,\n",
    "        'num_reviews': num_reviews,\n",
    "    }\n",
    "    information_list.append(laptop_info)\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f093735a",
   "metadata": {},
   "source": [
    "# Convert Dtypes\n",
    "\n",
    "Clean the data now for better utility later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(information_list)\n",
    "# change dtypes to best fit the data\n",
    "df['price_256GB_usd'] = df['price_256GB_usd'].astype('float')\n",
    "df['price_1024GB_usd'] = df['price_1024GB_usd'].astype('float')\n",
    "df['num_reviews'] = df['num_reviews'].astype('int')\n",
    "\n",
    "# save the data as csv\n",
    "df.to_csv('../data/scraped_laptop_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf1720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
